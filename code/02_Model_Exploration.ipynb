{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653f7b33-2710-4613-bc09-76678e666c0b",
   "metadata": {},
   "source": [
    "# 02: Model Exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53f3e0-192d-43d4-a50a-651fd4f42373",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679d55e8-0875-470a-b8f9-83fa9d84c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Lasso, Ridge, ElasticNetCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dceab-e5d1-4119-946e-817e2e0bf821",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6a418c-83f9-45ce-a4ae-4c563ccbeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_train = pd.read_csv('../data/train_clean.csv')\n",
    "ames_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e418161-e184-4c2f-b02f-72cd1ec03c9e",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2339274-ec25-4805-82a1-a37b33260fb3",
   "metadata": {},
   "source": [
    "### 3.1. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b624d109-96ae-48c8-a509-5db7bd44b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames_train.drop(columns = ['pid','saleprice'])\n",
    "y = ames_train['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334a9e15-71b7-412f-a9a6-598ea421db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b36baf-cac0-41cc-96a5-9bb68c6f9f42",
   "metadata": {},
   "source": [
    "### 3.2. One-Hot-Encoding, Scaling & Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06aba1e9-603e-4802-9061-999801a40f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists of the numerical and categorical features to use in the transformer\n",
    "\n",
    "numerical = [col for col in X_train._get_numeric_data().columns]\n",
    "categorical = [col for col in X_train.columns if col not in numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdecb87-2fdf-4384-80af-7c01ce08592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a categorical feature pipeline that will one hot encode the data\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "# Creating a numerical feature pipeline that will force the different unit data into a common scale\n",
    "num_pipe = Pipeline([('ss', StandardScaler())])\n",
    "\n",
    "\n",
    "# Creating a ColumnTransformer that will be used to apply the pipelines to their respective features\n",
    "transformer = ColumnTransformer([\n",
    "    ('cat', cat_pipe, categorical),\n",
    "    ('num', num_pipe, numerical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acb3c79-7b8e-4478-a27f-d526271c1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformer to the X_train and converting back to a DataFrame\n",
    "\n",
    "Xt_train = transformer.fit_transform(X_train)\n",
    "Xt_train = pd.DataFrame(Xt_train, columns = transformer.get_feature_names_out(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f9d7b1-7767-4f58-8dad-e2d39179d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformer to the X_val and converting back to a DataFrame\n",
    "\n",
    "Xt_val = transformer.transform(X_val)\n",
    "Xt_val = pd.DataFrame(Xt_val, columns = transformer.get_feature_names_out(X_val.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "58156739-6624-4810-b2ca-5518809ea962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train features: 79\n",
      "Xt_train features: 301\n"
     ]
    }
   ],
   "source": [
    "print('X_train features: ' + str(X_train.shape[1]))\n",
    "print('Xt_train features: ' + str(Xt_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4097c4c-2015-4a36-b250-7fd370e31470",
   "metadata": {},
   "source": [
    "Originally, there were 79 features in the dataset. After one-hot-encoding the categorical features, there are now 301 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290a670-5d5d-4ea3-b1ea-d7032dcfd3e8",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c61bb-bd60-4b59-994e-4d55fca85465",
   "metadata": {},
   "source": [
    "### 4.1. y_train & y_val statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6a7a245-2a19-4dfe-a620-984e88a212a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1640.000000\n",
       "mean     181718.527439\n",
       "std       79793.423579\n",
       "min       13100.000000\n",
       "25%      129900.000000\n",
       "50%      163000.000000\n",
       "75%      214600.000000\n",
       "max      611657.000000\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93704ac0-00bf-4d7e-9a7b-713e2f4f056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       411.000000\n",
       "mean     180476.819951\n",
       "std       77175.170846\n",
       "min       12789.000000\n",
       "25%      129225.000000\n",
       "50%      160000.000000\n",
       "75%      211000.000000\n",
       "max      451950.000000\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bf068-8ce8-4b6a-a7c1-991af067a2ea",
   "metadata": {},
   "source": [
    "With the intention of using the RMSE metric to evaluate the performance of the models, I've checked to see what the standard deviation of the y_train (79,793) and y_val (77,175) DataFrames are. The standard deviation indicates the amount of variability that is acceptable, and the RMSE will describe how far off the predicted values were from the actual values. Ideally, the RMSE should be less than the standard deviation.\n",
    "\n",
    "The R2 score will also be used and explains how much variability a model is able to explain. On a scale of 0 to 1, the higher the score, the better. And when comparing the train and validation R2 scores, if the validation R2 score is higher than the train R score, then the model is likely to do well when applied to unseen data. On the other hand, if the train R2 score is higher than the validation R2 score, then the model is in danger of being overfit, and will likely not do well when applied to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f49b5e-e859-42ea-ae91-ae3b6bff82d8",
   "metadata": {},
   "source": [
    "### 4.2. Linear Regression #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a2a153-6780-45c2-8169-55bd066eab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting a linear regression to the training data\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d3c8e7-195d-49a2-866e-09e6212644a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439858723675133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train R2 score\n",
    "\n",
    "lr.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68072052-266a-4bb3-a229-ae2b4344239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0394188615477022e+21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation R2 score\n",
    "\n",
    "lr.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34e71e97-e7f4-4c5d-9995-4de41b4bb097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18879.193606386874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "\n",
    "mean_squared_error(y_train, lr.predict(Xt_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f27e86d-398e-4ee3-a745-1a65ffc60126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3480982442410043.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation RMSE\n",
    "\n",
    "mean_squared_error(y_val, lr.predict(Xt_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f3692-f9f4-40e9-a3d1-f2cabc8162fc",
   "metadata": {},
   "source": [
    "The linear regression model did not perform well. The train R2 score was 0.94, while the validation R2 score was in the negatives. The model is incredibly overfit, meaning that the model was trained too closely to the training data, and therefore, does not do well with unseen data. The train RMSE (18,879) was less than the train standard deviation (79,793), but the validation RMSE (3,480,982,442,410,043) way beyond the validation standard deviation (77,175)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7c0cc-dcd3-4fa5-8873-aa2aedfe954c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3. RidgeCV #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca8b303f-387e-47e4-b6d7-7cbc42dc8774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000000e+00, 1.12332403e+00, 1.26185688e+00, 1.41747416e+00,\n",
       "       1.59228279e+00, 1.78864953e+00, 2.00923300e+00, 2.25701972e+00,\n",
       "       2.53536449e+00, 2.84803587e+00, 3.19926714e+00, 3.59381366e+00,\n",
       "       4.03701726e+00, 4.53487851e+00, 5.09413801e+00, 5.72236766e+00,\n",
       "       6.42807312e+00, 7.22080902e+00, 8.11130831e+00, 9.11162756e+00,\n",
       "       1.02353102e+01, 1.14975700e+0...\n",
       "       6.89261210e+03, 7.74263683e+03, 8.69749003e+03, 9.77009957e+03,\n",
       "       1.09749877e+04, 1.23284674e+04, 1.38488637e+04, 1.55567614e+04,\n",
       "       1.74752840e+04, 1.96304065e+04, 2.20513074e+04, 2.47707636e+04,\n",
       "       2.78255940e+04, 3.12571585e+04, 3.51119173e+04, 3.94420606e+04,\n",
       "       4.43062146e+04, 4.97702356e+04, 5.59081018e+04, 6.28029144e+04,\n",
       "       7.05480231e+04, 7.92482898e+04, 8.90215085e+04, 1.00000000e+05]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting RidgeCV to the training data\n",
    "\n",
    "ridgecv = RidgeCV(alphas = np.logspace(0, 5, 100))\n",
    "\n",
    "ridgecv.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed3ddf65-1748-4c35-852b-fc04bb0b58bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.235310218990262"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best-performing alpha\n",
    "\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c679673-18e9-4eb7-92f1-0118dcbeb261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912682421854184"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train R2 score\n",
    "\n",
    "ridgecv.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b82696c9-5969-4c42-84d9-e68453f8f78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148016013374631"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation R2 score\n",
    "\n",
    "ridgecv.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d6945bf-3c5f-488b-a679-4b606a521baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23571.40623404403"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "\n",
    "mean_squared_error(y_train, ridgecv.predict(Xt_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d950961-c29f-459a-92a0-976d7c96b76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22499.057884853388"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation RMSE\n",
    "\n",
    "mean_squared_error(y_val, ridgecv.predict(Xt_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352220e-ec41-47a8-ba17-df9fbd8944f2",
   "metadata": {},
   "source": [
    "The RidgeCV model applies ridge (L2) regularization to a linear regression model. This means that features with large coefficients will be shrunk toward zero, thereby reducing model complexity to help prevent overfitting. The alpha parameter dictates the strength of the regularization, making it very important to get the alpha just right. Fortunately, given a range, the RidgeCV model itself can cross validate various alphas and fit the data according to the best-performing alpha.\n",
    "\n",
    "The best-performing alpha here is 10.24, and it allowed for a much better performing model, compared to the simple linear regression.\n",
    "\n",
    "- The train R2 score was 0.9127, and the validation R2 score was 0.9148. Having both scores in the 0.90s indicates that the model is performing well, and having a validation R2 score that's higher than the train R2 score means that the model does very well with unseen data. \n",
    "\n",
    "- The train RMSE (23,571) was less than the train standard deviation (79,793), and the validation RMSE (22,499) was less than the validation standard deviation (77,175)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a427d-318e-4545-a44f-a01c7883ed81",
   "metadata": {},
   "source": [
    "### 4.4. RidgeCV #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb4ceb90-7f48-4dbe-b0dc-1ef603a385ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([  1.        ,   1.04761575,   1.09749877,   1.149757  ,\n",
       "         1.20450354,   1.26185688,   1.32194115,   1.38488637,\n",
       "         1.45082878,   1.51991108,   1.59228279,   1.66810054,\n",
       "         1.7475284 ,   1.83073828,   1.91791026,   2.009233  ,\n",
       "         2.10490414,   2.20513074,   2.3101297 ,   2.42012826,\n",
       "         2.53536449,   2.65608778,   2.7825594 ,   2.91505306,\n",
       "         3.05385551,   3.19926714,   3.35160265,   3.51119173,\n",
       "         3.67837977,   3.85352859,   4.03701726,   4....\n",
       "        23.64489413,  24.77076356,  25.95024211,  27.18588243,\n",
       "        28.48035868,  29.8364724 ,  31.2571585 ,  32.74549163,\n",
       "        34.30469286,  35.93813664,  37.64935807,  39.44206059,\n",
       "        41.320124  ,  43.28761281,  45.34878508,  47.50810162,\n",
       "        49.77023564,  52.14008288,  54.62277218,  57.22367659,\n",
       "        59.94842503,  62.80291442,  65.79332247,  68.92612104,\n",
       "        72.20809018,  75.64633276,  79.24828984,  83.02175681,\n",
       "        86.97490026,  91.11627561,  95.45484567, 100.        ]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting RidgeCV to the training data\n",
    "\n",
    "ridgecv2 = RidgeCV(alphas = np.logspace(0, 2, 100))\n",
    "\n",
    "ridgecv2.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41bb2bb1-35eb-489b-b482-e903d1435979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.770099572992255"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best-performing alpha\n",
    "\n",
    "ridgecv2.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5829c0b-2280-44e6-8d65-c4ff07ed14df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130516203150741"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train R2 score\n",
    "\n",
    "ridgecv2.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9c0c72a-f95a-42f2-9586-825098aed93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9147778005079219"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation R2 score\n",
    "\n",
    "ridgecv2.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4aba527-9f13-4244-9a8f-bebddea47814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23416.82336432782"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "\n",
    "mean_squared_error(y_train, ridgecv2.predict(Xt_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5f881dd-1e45-436f-b878-27f360f91263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22509.156453719017"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation RMSE\n",
    "\n",
    "mean_squared_error(y_val, ridgecv2.predict(Xt_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b3db0-a459-400b-93f6-7441cd1a8558",
   "metadata": {},
   "source": [
    "Since the RidgeCV model did so well, I wanted to see if I could find a better performing alpha by focusing the range a bit more.\n",
    "\n",
    "The best-performing alpha here is 9.77, and the model performed very similarly to the first RidgeCV model.\n",
    "- The train R2 score increased slightly (0.9127 -> 0.9131), while the validation R2 score decreased slightly (0.9148 -> 0.91478).\n",
    "- The train RMSE decreased (23,571 -> 23,417), while the validation RMSE increased (22,499 -> 22,509).\n",
    "\n",
    "Though the train metrics improved, the opposite happened for the validation metrics. For this reason, the RidgeCV model with an alpha of 10.24 remains the best performer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c3efc-d369-4793-838d-98582e026c72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.5. LassoCV #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1ea3c9dd-194f-405e-9572-fee424b2ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e+00, 1.12332403e+00, 1.26185688e+00, 1.41747416e+00,\n",
       "       1.59228279e+00, 1.78864953e+00, 2.00923300e+00, 2.25701972e+00,\n",
       "       2.53536449e+00, 2.84803587e+00, 3.19926714e+00, 3.59381366e+00,\n",
       "       4.03701726e+00, 4.53487851e+00, 5.09413801e+00, 5.72236766e+00,\n",
       "       6.42807312e+00, 7.22080902e+00, 8.11130831e+00, 9.11162756e+00,\n",
       "       1.02353102e+01, 1.14975700e+0...\n",
       "       6.89261210e+03, 7.74263683e+03, 8.69749003e+03, 9.77009957e+03,\n",
       "       1.09749877e+04, 1.23284674e+04, 1.38488637e+04, 1.55567614e+04,\n",
       "       1.74752840e+04, 1.96304065e+04, 2.20513074e+04, 2.47707636e+04,\n",
       "       2.78255940e+04, 3.12571585e+04, 3.51119173e+04, 3.94420606e+04,\n",
       "       4.43062146e+04, 4.97702356e+04, 5.59081018e+04, 6.28029144e+04,\n",
       "       7.05480231e+04, 7.92482898e+04, 8.90215085e+04, 1.00000000e+05]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting LassoCV to the training data\n",
    "\n",
    "lassocv = LassoCV(alphas = np.logspace(0, 5, 100))\n",
    "\n",
    "lassocv.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3df97cb-b2e9-4df5-bfe7-0eff2c70c481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.02175681319744"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best-performing alpha\n",
    "\n",
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "65c40918-75c2-4baf-a729-340f9c65eacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features zeroed out\n",
    "\n",
    "len(list(filter(lambda x: (x == 0), lassocv.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01811d9a-a6eb-45f2-881c-52a6adc88ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features kept\n",
    "\n",
    "len(list(filter(lambda x: (x != 0), lassocv.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "38ced183-6021-4735-98ad-4e01e45e151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267987454892211"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train R2 score\n",
    "\n",
    "lassocv.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5e48deb0-b2d5-4e17-92be-0b46aa013c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258018008010389"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation R2 score\n",
    "\n",
    "lassocv.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa9c4383-9ff9-481e-9b53-26af6e5eef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21582.110603190427"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "\n",
    "mean_squared_error(y_train, lassocv.predict(Xt_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0f150026-5864-4469-b717-56a1325bbbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20996.422318041197"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation RMSE\n",
    "\n",
    "mean_squared_error(y_val, lassocv.predict(Xt_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e466f-f474-4667-bfae-836cbf8ee89c",
   "metadata": {},
   "source": [
    "The LassoCV model applies a lasso (L1) regularization to a linear regression model. This means that non-important feature coefficients will be zeroed out, and will be eliminated as features, allowing the model to focus on features of importance. This reduces model complexity and helps prevent overfitting. Again, the alpha parameter dictates the strength of the regularization, making it very important to get the alpha just right. Fortunately, given a range, the LassoCV model itself can cross validate various alphas and fit the data according to the best-performing alpha.\n",
    "\n",
    "The best-performing alpha here is 83.02. Of the 301 features, 173 were zeroed out, and 128 were kept. This allowed for a better performing model, compared to all previous models.\n",
    "- The train R2 score was 0.9268, and the validation R2 score was 0.9258.\n",
    "- The train RMSE (21,582) was less than the train standard deviation (79,793), and the validation RMSE (20,996) was less than the validation standard deviation (77,175).\n",
    "\n",
    "Though the validation R2 score here was not higher than the train R2 score, it wasn't off by very much, and both were in the 0.92s, which is higher than any of the previous R2 scores. The train and validation RMSEs were also decreased by about 2,000 and reached an all time low. This makes the LassoCV with an alpha of 83.02 the best-performer yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f05f64-4770-458a-9683-5014bdfc53b6",
   "metadata": {},
   "source": [
    "### 4.6. LassoCV #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2b133c5f-75f5-47e4-a860-e93eea1b3bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([  1.        ,   1.04761575,   1.09749877,   1.149757  ,\n",
       "         1.20450354,   1.26185688,   1.32194115,   1.38488637,\n",
       "         1.45082878,   1.51991108,   1.59228279,   1.66810054,\n",
       "         1.7475284 ,   1.83073828,   1.91791026,   2.009233  ,\n",
       "         2.10490414,   2.20513074,   2.3101297 ,   2.42012826,\n",
       "         2.53536449,   2.65608778,   2.7825594 ,   2.91505306,\n",
       "         3.05385551,   3.19926714,   3.35160265,   3.51119173,\n",
       "         3.67837977,   3.85352859,   4.03701726,   4....\n",
       "        23.64489413,  24.77076356,  25.95024211,  27.18588243,\n",
       "        28.48035868,  29.8364724 ,  31.2571585 ,  32.74549163,\n",
       "        34.30469286,  35.93813664,  37.64935807,  39.44206059,\n",
       "        41.320124  ,  43.28761281,  45.34878508,  47.50810162,\n",
       "        49.77023564,  52.14008288,  54.62277218,  57.22367659,\n",
       "        59.94842503,  62.80291442,  65.79332247,  68.92612104,\n",
       "        72.20809018,  75.64633276,  79.24828984,  83.02175681,\n",
       "        86.97490026,  91.11627561,  95.45484567, 100.        ]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting LassoCV to the training data\n",
    "\n",
    "lassocv2 = LassoCV(alphas = np.logspace(0, 2, 100))\n",
    "\n",
    "lassocv2.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2736568c-4a2e-4181-be6d-42e32be6d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.24828983539177"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best-performing alpha\n",
    "\n",
    "lassocv2.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b43fc3b-c81c-426f-b46a-55d5e92cdfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features zeroed out\n",
    "\n",
    "len(list(filter(lambda x: (x == 0), lassocv2.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c3ad7724-3255-48ba-adf2-bc971398a03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features kept\n",
    "\n",
    "len(list(filter(lambda x: (x != 0), lassocv2.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8b95eeb9-c293-465a-8c36-a3f534922129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9278583545708836"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train R2 score\n",
    "\n",
    "lassocv2.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "59c90b79-57aa-4bd6-abcf-3b3f4983a499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261632153716907"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation R2 score\n",
    "\n",
    "lassocv2.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6cc2db96-3df2-4b62-a164-360a32558ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21425.337591754054"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "\n",
    "mean_squared_error(y_train, lassocv2.predict(Xt_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "837395fe-8fe4-4f46-a3db-3beff4880ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20945.22379651986"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation RMSE\n",
    "\n",
    "mean_squared_error(y_val, lassocv2.predict(Xt_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e78e0a-f3a7-4fa2-baef-1f39b9049ca8",
   "metadata": {},
   "source": [
    "Since the LassoCV model did so well, I wanted to see if I could find a better performing alpha by focusing the range a bit more.\n",
    "\n",
    "The best-performing alpha here is 79.25. As in the previous LassoCV model, of the 301 features, 173 were zeroed out, and 128 were kept.\n",
    "\n",
    "- The train R2 score increased slightly (0.9268 -> 0.9279), as did the validation R2 score (0.9258 -> 0.9262).\n",
    "- The train RMSE decreased (21,582 -> 21,425), while the validation RMSE increased (20,996 -> 20,945).\n",
    "\n",
    "Both the train and the validation metrics improved, and the LassoCV model with an alpha of 79.25 is now the best-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fce6c-f7d2-48e6-9c72-affbcc253f74",
   "metadata": {},
   "source": [
    "### 4.7. ElasticNetCV #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9c4a0b82-4541-4f1b-af10-73cc67562800",
   "metadata": {},
   "outputs": [],
   "source": [
    "enetcv = ElasticNetCV(alphas = np.logspace(0, 2, 100), l1_ratio=[.1, .5, .7, .9, .95, .99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2d76d176-1855-4739-a119-1bbc4577700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=array([  1.        ,   1.04761575,   1.09749877,   1.149757  ,\n",
       "         1.20450354,   1.26185688,   1.32194115,   1.38488637,\n",
       "         1.45082878,   1.51991108,   1.59228279,   1.66810054,\n",
       "         1.7475284 ,   1.83073828,   1.91791026,   2.009233  ,\n",
       "         2.10490414,   2.20513074,   2.3101297 ,   2.42012826,\n",
       "         2.53536449,   2.65608778,   2.7825594 ,   2.91505306,\n",
       "         3.05385551,   3.19926714,   3.35160265,   3.51119173,\n",
       "         3.67837977,   3.85352859,   4.037017...\n",
       "        28.48035868,  29.8364724 ,  31.2571585 ,  32.74549163,\n",
       "        34.30469286,  35.93813664,  37.64935807,  39.44206059,\n",
       "        41.320124  ,  43.28761281,  45.34878508,  47.50810162,\n",
       "        49.77023564,  52.14008288,  54.62277218,  57.22367659,\n",
       "        59.94842503,  62.80291442,  65.79332247,  68.92612104,\n",
       "        72.20809018,  75.64633276,  79.24828984,  83.02175681,\n",
       "        86.97490026,  91.11627561,  95.45484567, 100.        ]),\n",
       "             l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enetcv.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1a4b498e-e0bd-4e67-9889-6f8c4f7c35ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.24828983539177"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enetcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dcf96c6f-f14b-4806-aca0-df8e7be3448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features zeroed out\n",
    "\n",
    "len(list(filter(lambda x: (x == 0), enetcv.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2353f5ee-72fa-4b59-9066-37ec2b070918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features kept\n",
    "\n",
    "len(list(filter(lambda x: (x != 0), enetcv.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fc26a3de-584a-4315-a9e7-6558a2fed9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9278583545708836"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enetcv.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "22d198c7-a0dd-4d27-9bb9-14b0a7de4a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261632153716907"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enetcv.score(Xt_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ef223c18-1b7b-4c7c-9644-c14f5b7dae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21425.337591754054"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, enetcv.predict(Xt_train))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "edcd8e45-fb9d-4701-a20f-bfcffe8c23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20945.22379651986"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, enetcv.predict(Xt_val))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305aa4d0-fccf-4d9f-95cc-58974eb91b57",
   "metadata": {},
   "source": [
    "The ElasticNetCV model can be used to apply a combination of both ridge (L2) and lasso (L1) regularization to a linear regression model. Given ranges, the model can find the best-performing alpha as well as the best-performing ratio between the regularizations.\n",
    "\n",
    "It turns out that this model performs best when using a full lasso regularization, seeing that it found the best-performing alpha to be 79.25, just as the second LassoCV model did. As a result, it returned the same metrics as that model did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508e0e7-e344-482b-9f0a-f037bd47ff72",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Summary\n",
    "\n",
    "Of all the models, the LassoCV can be said to be the best-performer when using the alpha of 79.25. Though the ElasticNetCV model returned the same results, it only did so because it was using a full lasso regularization. As a result, the LassoCV model with the alpha of 79.25 will be used to draw insights from."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
